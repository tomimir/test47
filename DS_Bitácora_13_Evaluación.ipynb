{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DS_Bitácora_13_Evaluación.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjehwI9oQ8LI"
      },
      "source": [
        "# Evaluación de Modelos\n",
        "\n",
        "\n",
        "En este notebook veremos cómo implementar los pasos necesarios para una correcta evaluación de modelos. Las secciones del notebook son:\n",
        "1. Comenzaremos con nuestro infaltable ejemplo con el dataset de Iris, implementando un `train_test_split` y, luego, optimización de hiperparámetros. A esta altura, ya debés estar cansado/a de este dataset. Pero si entiendes bien este ejemplo, el resto será más fácil.\n",
        "2. En esta sección, debes aplicar lo aprendido en el dataset de Titanic.\n",
        "\n",
        "## 1. Train-Test Split y Optimización de Hiperparámetros\n",
        "\n",
        "### 1.1 Train-Test Split\n",
        "\n",
        "1. Carga del dataset y separa en `X` e `y` como venimos haciendo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Gkg2POFAQ8LK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgawTupQ8LT"
      },
      "source": [
        "iris = load_iris()\n",
        "data = COMPLETAR\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "757FJVHJQ8LZ"
      },
      "source": [
        "X = COMPLETAR\n",
        "y = COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOnfRYlcQ8Lg"
      },
      "source": [
        "Luego, como aprendimos, vamos a separar el dataset en conjuntos de entrenamiento `X_train, y_train` y de testeo `X_test,y_test` usando la función `train_test_split` de Scikit-Learn (¡recuerda mirar su documentación e importarla!). Esto lo hacemos para separar parte de los datos `X_test,y_test` con los cuales **no vamos a entrenar el modelo, sino que vamos a usarlos únicamente para evaluar su desempeño**.\n",
        "\n",
        "2. Separa `X` e `y`, tomando en las variables `X_train, y_train` un 70% para entrenamiento y en las variables `X_test,y_test` un 30% para evaluación. Recuerda fijar el `random_state`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rifKTjUIQ8Lh"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyy8E2wGQ8Lm"
      },
      "source": [
        "3. Crea un modelo de vecino más cercanos y entrénalo sobre el conjunto de Train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjKQmMKaQ8Ln"
      },
      "source": [
        "# COMPLETAR\n",
        "clf_knn = COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFFgR5QlQ8Lv"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HnmxmE_Q8L2"
      },
      "source": [
        "4. Predice las etiquetas sobre el conjunto de Train y sobre el conjunto de Test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgkgArneQ8L4"
      },
      "source": [
        "y_train_pred = # COMPLETAR\n",
        "y_test_pred = # COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj_RS-AeQ8MB"
      },
      "source": [
        "5. Evalúa el desempeño del modelo usando la función `accuracy_score` y la matriz de confusión sobre ambos conjuntos (Train y Test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xVMmRq-Q8MD"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfW_1gfWQ8MI"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR6NpfsYQ8MO"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aAO_wATQ8MT"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW0FNiu-Q8MY"
      },
      "source": [
        "**Para Pensar**:\n",
        "\n",
        "1. ¿Qué ocurre con el desempeño con número de vecinos igual a 1 y un número de vecinos grande (del orden del tamaño del dataset?\n",
        "2. ¿Cuál será el número óptimo de vecinos para este modelo?¿Cómo podrías obtenerlo?\n",
        "\n",
        "\n",
        "### 1.2 Encontrando el mejor hiperparámetro\n",
        "\n",
        "Durante el entrenamiento, el modelo ajusta ciertas característica intrínsecas que llamamos parámetros. Por ejemplo, un árbol de decisión debe decidir automáticamente con qué umbrales comparar ciertos atributos en cada nodo. Pero los hiperparámetros son características que debemos definir nosotros; por ejemplo, la profundidad del árbol o el número de vecinos. Optimización de hiperparámetros se lleva un tiempo considerable en un flujo de ML, y si bien hay técnicas más o menos automáticas para hacerlo, al final siempre tiene algo artesanal. Además, está fuertemente ligado a la evaluación de nuestro modelo: siempre optimizamos hiperparámetros dada cierta métrica. Esta métrica se define en función del problema, nuestras necesidades y posibilidades.\n",
        " \n",
        "La variación de hiperparámetros está asociada a la complejidad del modelo, al overfitting y al underfitting. Por ejemplo, en el caso de árboles de decisión, un árbol de profundidad 1 es mucho más sencillo que uno de profundidad 10. En el primer caso, el modelo tenderá a estar subajustado, mientras que en el segundo, sobreajustado. En esta sección vamos a empezar haciendo la optimización más sencilla posible, un sólo hiperparámetro. En este caso, una buena opción es probar con muchos valores del hiperparámetro, y graficar su desempeño en función de estos valores. De esta forma, variamos la complejidad del modelo y observámos como impacta en su desempeño. Estas curvas se llaman curvas de validación, y se pueden hacer automáticamente desde Scikit-Learn, pero primero las vamos a hacer *a mano* para entender bien su funcionamiento.\n",
        "\n",
        "Vamos a ver esto en el caso de un modelo de vecinos más cercanos. Para ello, debemos evaluar la exactitud y del modelo en el set de train y test para distintos valores del parámetro `n_neighbors`. Vamos entonces a repetir el esquema de: **definir, entrenar y predecir** en un loop `for` que recorre una lista con distintos valores de vecinos.\n",
        "\n",
        "**Ejercicio**: Trabaja en el siguiente bloque de codigo, de manera de completar con valores las listas `lista_accuracy_train` y `lista_accuracy_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7cZgKuiQ8MZ"
      },
      "source": [
        "# Definimos las listas vacias para los valores de accuracy deseados\n",
        "lista_accuracy_train = []\n",
        "lista_accuracy_test = []\n",
        "\n",
        "# Definimos la lista de valores de k que vamos a explorar\n",
        "k_vecinos = [1,2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,50]\n",
        "\n",
        "# Generamos un loop sobre los distintos valores de k \n",
        "for k in k_vecinos:\n",
        "    \n",
        "    # Vamos a repetir el siguiente bloque de código\n",
        "    \n",
        "    # Definir el modelo con el valor de vecinos deseado\n",
        "    clf = KNeighborsClassifier(n_neighbors= COMPLETAR)\n",
        "    \n",
        "    # Entrenar el modelo\n",
        "    clf.fit(COMPLETAR)\n",
        "    \n",
        "    # Predecir y evaluar sobre el set de entrenamiento\n",
        "    y_train_pred = COMPLETAR\n",
        "    train_acc = accuracy_score(COMPLETAR)\n",
        "    \n",
        "    # Predecir y evaluar sobre el set de evaluación\n",
        "    y_test_pred = COMPLETAR\n",
        "    test_acc = accuracy_score(COMPLETAR)\n",
        "    \n",
        "    # Agregar la información a las listas\n",
        "    lista_accuracy_train.append(COMPLETAR)\n",
        "    lista_accuracy_test.append(COMPLETAR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40RVix7sQ8Mg"
      },
      "source": [
        "**Ejercicio**: Realiza un gráfico que muestre la curvas de accuracy en el set de entrenamiento (`lista_accuracy_train`) y accuracy en el set de testeo (`lista_accuracy_test`) en función del numero de vecinos (`k_vecinos`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_D7O-w8Q8Mh"
      },
      "source": [
        "plt.plot(COMPLETAR,'o-',label='train' )\n",
        "plt.plot(COMPLETAR,'o-',label='test')\n",
        "plt.legend()\n",
        "plt.xlabel(COMPLETAR)\n",
        "plt.ylabel(COMPLETAR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMFdq5mWQ8Mm"
      },
      "source": [
        "**Para pensar**: ¿cuál será el mejor hiperparámetro?¿En que región hay sobre-ajuste y en cuál sub-ajuste?\n",
        "\n",
        "Te dejamos una celda que puedes correr para observar distintas fronteras de decisión obtenidas para distintos valores del número de vecinos. ¿Notas para qué número de vecinos y en qué región está sobreajustando?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwMYgynLQ8Mn"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "X = data[['petal length (cm)', 'petal width (cm)']].values\n",
        "\n",
        "y = data.target\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "for k in [1,5,25,50]:\n",
        "    \n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf = KNeighborsClassifier(n_neighbors=k)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
        "\n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
        "                edgecolor='k', s=20)\n",
        "    \n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"Clasificador KNN con k = %i\"% (k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWp-rz-Q8Mt"
      },
      "source": [
        "**Curvas de validacíon en Scikit-Learn**\n",
        "\n",
        "Mencionamos que puedes hacer curvas de validación en Scikit-Learn; puedes encontrar su documentación [aquí](https://scikit-learn.org/stable/modules/learning_curve.html), pero utilizan algo que todavía no vimos, Validación Cruzada. Sin embargo, puedes mirar la documentación para ir familiarizándote.\n",
        "\n",
        "**Ejercicio:** Repite entrenamiento, evaluación, optimización de hiperparámetro (profundidad) y visualización de fronteras para un`DecisionTreeClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzvTyQH0Q8Mt"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe2kBQEHQ8Mz"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFyl-I_-Q8M6"
      },
      "source": [
        "# Definimos las listas vacias para los valores de accuracy deseados\n",
        "lista_accuracy_train = []\n",
        "lista_accuracy_test = []\n",
        "\n",
        "# Definimos la lista de valores de max_depth que vamos a explorar\n",
        "max_depths = [1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# Generamos un loop sobre los distintos valores de profundidad \n",
        "for max_depth in max_depths:\n",
        "    # COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkKg15QtQ8NC"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBjA9EWsQ8NH"
      },
      "source": [
        "X = data[['petal length (cm)', 'petal width (cm)']].values\n",
        "y = data.target\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# Create color maps\n",
        "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "for max_depth in [1,3,5,10]:\n",
        "    \n",
        "    # we create an instance of Neighbours Classifier and fit the data.\n",
        "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
        "\n",
        "    # Plot also the training points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
        "                edgecolor='k', s=20)\n",
        "    \n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"Clasificador DT con profundidad = %i\"% (max_depth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjv2W8E-Q8NL"
      },
      "source": [
        "### 2. Dataset Titanic\n",
        "\n",
        "Nuevamente, vamos a trabajar con el dataset del Titanic. La consigna consiste en:\n",
        "\n",
        "1. Generar dos casos benchmark para este dataset. ¿Cuáles se te ocurren? Hay una pista en el notebook anterior.\n",
        "1. Encontrar los mejores parámetros para profundidad y número de vecinos para un modelo de árbol de decisión y kNN, respectivamente. No te olvides de agregar un `train_test_split`, predecir sobre `X_train` y `X_test` y evaluar el desempeño de los modelos sobre esos conjuntos. \n",
        "1. Evaluar precisión, exhaustividad y F-Score para los modelos con los mejores hiperparámetros. Existen varias funciones de Scikit-Learn que puedes usar. Puedes consultar la información [aquí](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics). Es importante que leas **detalladamente** la documentación de la función que elijas."
      ]
    }
  ]
}