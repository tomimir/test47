{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnivNavMX9b5"
   },
   "source": [
    "# Árboles de decisión y k-vecinos más cercanos\n",
    "\n",
    "En este notebook trabajaremos con los dos modelos fundamentales de Machine Learning, Árboles de Decisión y k-vecinos más cercanos (kNN, k-nearest neighbors). Para ello, seguiremos utilizando el Iris Dataset y, luego, usaremos uno nuevo, el dataset de Titanic. El notebook está dividido en tres partes: \n",
    "\n",
    "1. kNN con Iris Dataset.\n",
    "1. Construcción de un árbol de decisión *a mano*. Cálculo de Impureza y Ganancia Gini.\n",
    "1. Titanic + Árboles de Decisión en Scikit-Learn.\n",
    "\n",
    "\n",
    "## 1. kNN: k-Nearest Neighbors - Challenge\n",
    "\n",
    "Para comenzar, vamos a trabajar con un dataset que ya conocemos, el de Iris. El flujo de trabajo será exactamente igual que el que hicieron en el notebook anterior para el `DecisionTreeClassifier`, pero en lugar de usar ese clasificador, deberán usar uno de vecinos más cercanos. Busca en la documentación de Scikit-Learn cómo debes importar ese clasificador. Recuerda que, debido a la implementación orientada a objetos de Scikit-Learn, **todos los modelos se entrenan y se usan de la misma forma**.\n",
    "\n",
    "1. Cargamos el dataset. Esta sección va de regalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JE2-sihRX9b9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9fz57mJX9cR"
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "data = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwEIkxwfX9cl"
   },
   "source": [
    "2. Separar del dataframe dos atributos y las etiquetas. Llamar `X` a los features e `y` a las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtWeRj7eX9co"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldmb5P-AX9c2"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0VjINXjX9dE"
   },
   "source": [
    "3. Importa y crea un un modelo de clasificación de vecinos más cercanos con los argumentos por defecto. ¿Cuáles son? Ten la documentación a mano y asegúrate que entiendes cada argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqd_oOX5X9dG"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQhp6tfmX9dU"
   },
   "source": [
    "4. Entrenar el clasificador que creaste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiwleN3HX9dW"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZC2AvVLdX9di"
   },
   "source": [
    "5. Predecir con el modelo las etiquetas sobre todo `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDTpn4hQX9dl"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMkMdk5AX9du"
   },
   "source": [
    "6. Evaluar la performance del modelo usando `accuracy_score` y `confusion_matrix`. ¿Cuáles clases se confunden entre sí?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6GGdu_RX9dw"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHNC0qZrX9d8"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gk77FC0X9eG"
   },
   "source": [
    "7. Visualiza las fronteras de decisión obtenidas. Recuerda copiar el código del notebook anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY4ElzTIX9eJ"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i8cVQHqX9eU"
   },
   "source": [
    "8. ¿Qué ocurre con el desempeño a medida que modificas el número de vecinos?¿Y con las fronteras de decisión obtenidas? Mira en particular qué ocurre con número de vecinos igual a 1 y al tamaño del dataset (150).\n",
    "\n",
    "9. Vuelve a entrenar, pero esta vez agregando más features a `X`. ¿Mejora o empeora el desempeño?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q26mQZZIX9eX"
   },
   "source": [
    "## 2. Construcción de un árbol de decisión *a mano*\n",
    "\n",
    "Es raro que, como Data Scientist, tengas que programar un modelo, al menos en esta etapa de tu carrera. En general, existen muchas librerías con implementaciones de diferente métodos al alcance de la mano. Sin embargo, hacer una implementación rápida, aunque sea sencilla, ayuda comprender mejor algunos detalles. \n",
    "\n",
    "En esta sección vamos a programar la consulta de un árbol de decisión y, luego, calcular algunas impurezas Gini. Todo esto lo implementa Scikit-Learn de forma automática, pero hacerlo te ayudará a comprender mejor los árboles de decisión.\n",
    "\n",
    "En la bitácora 07, Seaborn, te mencionamos brevemente el dataset de Titanic, que podías mirar en la competencia Kaggle Titanic: [Machine Learning from Disaster](https://www.kaggle.com/c/titanic). Hoy vamos a empezar a utilizarlo. En la descarga te dejamos una versión simplificada y filtrada de este dataset. Qué representa cada atributo puedes mirarlo en la página de Kaggle, pero te aclaramos que la columna `Sex`, en nuestro caso, refiere al género, donde `0` es hombre y `1` es mujer.\n",
    "\n",
    "**Ejercicio:** Carga el dataset de Titanic y tomate un rato para estudiar sus características. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l5gImVYX9eY"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcKpY61lX9ek"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-xda0NFX9es"
   },
   "source": [
    "### 2.1 Árbol de decisión *a mano*\n",
    "\n",
    "Ahora sí, manos a la obra.\n",
    "\n",
    "\n",
    "**NOTA**: LEER HASTA EL FINAL ANTES DE MODIFICAR EL CÓDIGO.\n",
    "\n",
    "En primer lugar, vamos a definir algunas funciones que serán de utilidad.\n",
    "\n",
    "* La función `accuracy`, dada las etiquetas que ustedes predigan y las etiquetas reales, calcula la medida de performance, en este caso, la exactitud. **No la tienes que modificar, pero presta atención a su implementación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6eodK4hX9eu"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_predicted, y_real):\n",
    "    mask = np.array(y_predicted) == np.array(y_real)\n",
    "    return mask.sum()/len(y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZv7pwKaX9e6"
   },
   "source": [
    "* La función `predict_instance`, dada una instancia x con sus atributos, predice si sobrevivió o no. **Es la única función que tendrás que modificar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CmpOTciX9e7"
   },
   "outputs": [],
   "source": [
    "def predict_instance(x):\n",
    "    '''\n",
    "    Modificar las siguientes líneas de codigo. \n",
    "    Este será su algoritmo algoritmo para predecir si sobrevivirá o no por instancia.\n",
    "    La variable prediction debe contener la etiqueta 0 o 1 \n",
    "    \n",
    "    Algunas opciones son: predecir que nadie sobrevivio, que todos sobrevivieron,\n",
    "    predecir al azar, y usar lo aprendido cuando exploramos el dataset de Titanic\n",
    "    '''\n",
    "    prediction = 0\n",
    "    \n",
    "    ### UNA POSIBLE FORMA DE EMPEZAR:\n",
    "#     if x.Age < 12:\n",
    "#         prediction = 1\n",
    "#     else:\n",
    "#         prediction = 0\n",
    "#     # FIN DE COMPLETAR\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqQXbJ6jX9fF"
   },
   "source": [
    "* Por último, la función `predict` toma todo las instancias `X` y, usando la función que definieron antes, predice para cada una de ellas si sobrevivió o no. **No la tienes que modificar, pero presta atención a su implementación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ugh2HtYX9fH"
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    y_predicted = []\n",
    "    for x in X.itertuples(): \n",
    "        y_i = predict_instance(x) \n",
    "        y_predicted.append(y_i)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5tnqbwEX9fP"
   },
   "source": [
    "**Consigna**\n",
    "\n",
    "1. Cargar el dataset de Titanic y separar en una variable `X` los atributos que usarás para predecir, y en una variable `y` la etiqueta que quieres predecir. En este caso, si sobrevivió o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5NXekO8X9fR"
   },
   "outputs": [],
   "source": [
    "X = COMPLETAR\n",
    "y = COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEyXgdD1X9fZ"
   },
   "source": [
    "2. Usar los datos `X` para predecir si los pasajeros sobrevivieron o no utilizando la función `predict`. **No tienes que modificar ninguna de las funciones por ahora**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beyE81L-X9fb"
   },
   "outputs": [],
   "source": [
    "y_pred = COMPLETAR\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RbV2oCNX9fi"
   },
   "source": [
    "3. Calcula la medida de performance entre las etiquetas reales `y` y las etiquetas predichas `y_pred` con la función `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370v7mWOX9fj"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yKvaJ-FX9fs"
   },
   "source": [
    "4. Calcula la matriz de confusión con Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_yoXXpfX9ft"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebku0lHfX9f1"
   },
   "source": [
    "**Ejercicio**: modifica `predict_instance` de forma tal de mejorar el resultado recién obtenido. Tal vez te sirva de pista, para arrancar, la famosa frase, \"mujeres y niños primero\".\n",
    "\n",
    "**Para pensar:** las performances asociadas a predecir todos `0` (nadie sobrevivió), todos `1` (todos sobrevivieron), y predecir al azar son muy importantes para evaluar nuestro trabajo. ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UoO0B4IX9f2"
   },
   "source": [
    "### 2.2 Cálculo de Impureza y Ganancia Gini\n",
    "\n",
    "Ahora vamos a calcular cuán buena es la *pregunta* del género y clase para separar las muestras usando la impureza Gini. Para ello:\n",
    "\n",
    "**Ejercicio:** calcula la impureza inicial del dataset. Ayuda: recuerda que en la variable `y` ya separaste las etiquetas. Si es un objeto de Pandas, tal vez la función `value_counts()` puede ser útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npL16KAkX9f4"
   },
   "outputs": [],
   "source": [
    "muestras_neg, muestras_pos = COMPLETAR\n",
    "N = COMPLETAR\n",
    "gini_inicial = 1 - COMPLETAR - COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0FHv2dYX9gB"
   },
   "outputs": [],
   "source": [
    "print(gini_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvQZL3oEX9gM"
   },
   "source": [
    "**Ejercicio:** calcula la impureza Gini luego de separar por el género. Recuerda que tienes que calcular la impureza en dos hojas - una correspondiente a género masculino y otra al femenino - y luego hacer un promedio ponderado. Para eso, puede ser conveniente crear una máscara y reciclar código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hwrrwph4X9gN"
   },
   "outputs": [],
   "source": [
    "mascara = COMPLETAR\n",
    "y_female = y[COMPLETAR]\n",
    "y_male = y[COMPLETAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhcQHRTbX9gW"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# COMPLETAR\n",
    "gini_female = COMPLETAR\n",
    "print(gini_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L9Dqs7ZX9ge"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "print(gini_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGT5pSTEX9gk"
   },
   "outputs": [],
   "source": [
    "print('Impureza Gini al separar por Genero:',(y_female.size*gini_female + y_male.size*gini_male)/y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqRQBsETX9gs"
   },
   "source": [
    "**Ejercicio Opcional:** calcula la impureza Gini luego de separar por clase. Recuerda que tienes que calcular la impureza en tres hojas y luego hacer un promedio ponderado. Para eso, puede ser conveniente crear tres máscaras y reciclar código anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQLzc4SAX9gu"
   },
   "outputs": [],
   "source": [
    "# PRIMERA CLASE\n",
    "mascara = df.Pclass == COMPLETAR\n",
    "y_1 = y[mascara]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcugPPYfX9g1"
   },
   "outputs": [],
   "source": [
    "muestras_neg, muestras_pos = COMPLETAR\n",
    "N = COMPLETAR\n",
    "gini_1 = COMPLETAR\n",
    "print(gini_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp3oAIOzX9g9"
   },
   "outputs": [],
   "source": [
    "# SEGUNDA CLASE\n",
    "mascara = COMPLETAR\n",
    "y_2 = COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocP0m6W2X9hD"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "print(gini_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSbzIyqFX9hJ"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR - TERCERA CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QIkaIXqX9hP"
   },
   "outputs": [],
   "source": [
    "print('Impureza Gini al separar por clase:', (y_1.size*gini_1 + y_2.size*gini_2 + y_3.size*gini_3)/y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsGHv2lNX9hW"
   },
   "source": [
    "**¿Cuál tiene una mayor ganancia Gini?¿Concuerda con lo visto hasta ahora?**\n",
    "\n",
    "**Para pensar:** ¿cómo modificarías el código para calcular la ganancia Gini al separar por edad? Por ejemplo, al separar por mayor de 12 años y menor de 12 años.\n",
    "\n",
    "### 3. Titanic + Árboles de Decisión en Scikit-Learn\n",
    "\n",
    "Si todavía te quedan energías, entrena un árbol de decisión de Scikit-Learn en el dataset de Titanic. Para ello, recibla código de este notebook y del anterior. Algunas recomendaciones:\n",
    "1. Experimenta con distintas profundidades y visualizar el árbol obtenidos con la función `plot_tree` del módulo `tree` de Scikit-Learn.\n",
    "1. Evalúa su desempeño calculando la exactitud y viendo su matriz de confusión.\n",
    "1. Observa la importancia asignada a cada atributo (`feature_importances_`). En el notebook anterior podrás encontrar el código para realizar un gráfico de barras que te puede ser útil.\n",
    "1. Si seleccionas dos atributos, pueden observar las fronteras de decisión.\n",
    "\n",
    "¿Te parece que lo obtenido concuerda con lo que esperabas?¿Qué puedes aprender de la tragedia del Titanic viendo el árbol de decisíon y la importancia de cada atributo (feature)?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "p-xda0NFX9es",
    "RsGHv2lNX9hW"
   ],
   "name": "DS_Bitácora_12_DTyKNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
